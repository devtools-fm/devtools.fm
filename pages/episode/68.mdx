---
title: Eric Elliott - SudoLang
youtube: https://www.youtube.com/watch?v=2EAJLYmKiog
spotify: https://podcasters.spotify.com/pod/show/devtoolsfm/episodes/Eric-Elliott---SudoLang-e2a1eun
tags: technology, programming, developer tools, devtools, javascript, ai, artificial intelligence, machine learning, gpt3, gpt4, chatgpt, sudolang, pseudo, pseudo code, code, programming language, language model, language models, react, python, javascript, solidity
---

<!-- TAB: SHOW NOTES -->

This week we talk with Eric Elliott about his new project SudoLang.
SudoLang is a pseudo code programming language that runs on top of AI language models like GPT-4.
By leveraging the power of AI, SudoLang enables you to just write what you want your program to do in plain english and it will write the code for you.
We also discuss the future of coding with AI and how it can help you be more productive.

- http://devanywhere.io/
- https://twitter.com/_ericelliott?lang=en
- https://twitter.com/SudoLang

Sponsored By Raycast (https://www.raycast.com/)

Become a paid subscriber our patreon, spotify, or apple podcasts for the full episode.

- https://www.patreon.com/devtoolsfm
- https://podcasters.spotify.com/pod/show/devtoolsfm/subscribe
- https://podcasts.apple.com/us/podcast/devtools-fm/id1566647758
- https://www.youtube.com/@devtoolsfm/membership

<!-- LINKS -->

### Tooltips

#### Andrew

- https://www.cursor.so

#### Justin

- https://github.com/binwiederhier/ntfy
- https://docs.astro.build/en/guides/view-transitions/

### Eric

- VS Code
- GitHub Co-Pilot
- ChatGPT Advanced Data Analysis (GPT-4 + Python Interpreter)
- DailyBot https://www.dailybot.com/
- SonarCloud https://sonarcloud.io/

<!-- TAB: SECTIONS -->

[00:01:21] Eric's AI Background
[00:03:19] Developing with AI
[00:08:35] Ad
[00:09:59] Intro to SudoLang
[00:19:29] What does it work for?
[00:31:05] Thinking in SudoLang
[00:42:18] Future of Coding with A
[01:01:44] Tooltips

<!-- TAB: TRANSCRIPT -->

# Episode 68 - Free

**Eric:** sudo lang is a psuedocode programming language that runs on top of AI language models like G PT four. You don't need to provide the Sudo Lang spec for the AI to understand it. In other words, it knows about all of the features that sudolang has already because the features are really drawn from the larger uni verse of what other programming languages have already done before. For it to understand the programming language. It just does, it just infers it naturally.

**Andrew:** Hello, welcome to the Dev tools FM podcast. This is a podcast about developer tools and the people who make 'em. I'm Andrew, and this is my co-host Justin.

**Justin:** Hey everyone. Uh, we're really excited to have Eric Elliot on the, the podcast today. Uh, if you've been around Twitter for any amount of time, especially in the tech space, you've probably seen Eric, uh, pop, pop-up, uh, writes a lot of educational content. Uh, and we were just chatting about this before where it's like so fun to have you on because, you know, we've just like seen you online so much.

So really excited to have you on and really excited to talk out about a project that you've been working on called Pseudo Ling. But before we dive into that, would you like to tell our listeners a little bit more about yourself?

#### [00:01:21] Eric's AI Background

**Eric:** Sure. Um, hi, I'm Eric Elliot. Uh, I've been coding since I was about six and building lots of interesting things. I've, uh, helped build a lot of cool stuff like Adobe Creative Cloud. Um, I helped build YouTube artist pages, um, bunch of interesting little projects. I did, um, a Stanford Research Institute, AI spinoff.

I was a tech lead. Uh, we were webby nominated for our work on the Wall Street Journal World Stream. Um, I think that was like TikTok before TikTok. It was used by. N B C C B S B B C, uh, e s p n, bunch of major broadcasters to do, um, video during their shows from fans. So fans would watch the show live, record little videos, post them to their accounts, and then the, the broadcasters would pick the fan videos and play them on air and stuff.

Um, anyway, that's kind of me. I'm happy to be here. Um, I've been interested in AI since I was a little kid. I learned, um, I learned about AI because I was, when I was six, I wanted to play, I wanted to make video games, but I didn't know how. So we asked, I asked my friend, and my friend was like, I don't know.

So we asked his dad. His dad reached up on a high shelf and gave us a book. And inside that book, it was full of video games, source code that kids could type in and play video games, um, make their own video games and play them. So that's how I learned. And the graphical games were. Longer than the text-based games, and I thought that meant harder.

I was six. I didn't know anything, so I decided to concentrate on text adventure games. So from the time I was six until my late teens, I built a bunch of text adventure games and that got me into natural language understanding, which led me into ai, which led me into building my own models, uh, as a teenager.

Uh, so I've been into AI since I was a kid for as long as I can remember.

#### [00:03:19] Developing with AI

**Andrew:** Yeah. So, uh, with the recent, uh, huge interest in AI and I'd say like leaps in, uh, our ability to do things with ai, um, what's like the state of AI coding lately, like before we get to pseudo laying and all of that, like, how can AI help me code.

**Eric:** So, um, AI can help in a lot of ways. Of course, you know, GitHub copilot dropped a while back now, and I think a lot, most people know about that now. And most people have had some experience using AI assisted coding in some way. Uh, if you haven't, jump into it and start using it right away, because even just using GitHub co-pilot, regular users of GitHub, GitHub co-pilot are about twice as productive as people who are not using it and also more likely to be successful in their, in their coding.

So, um, and there's a GitHub released a study, uh, that demonstrated that stuff, so definitely start using that if you haven't. Um, and then chat.GPT, especially GPT4. The GPT4 model is pretty good at writing code for you. So very, uh, very often if you have a small enough problem and you describe it really succinctly and say, Hey, I'd like a JavaScript function that does this.

Right. Um, Pretty good chance it's gonna be able to do it for you, uh, which is fantastic. And what I find most interesting is when I'm approaching like an unfamiliar framework or an unfamiliar language, like um, my Python skills are not quite as good as my JavaScript skills, for instance, right? I can go into chatGPT and say, Hey, I need a Python function that does this.

And uh, it will figure out like the standard libraries to use the most common libraries and things like that and pull them in for you. And so I've had to do all kinds of really interesting things, data visualizations and stuff like that. Um, uh, very often, like if you wanted to do something like a graphical analysis of an MP three file or something, uh, a music file or audio file first, you'd have to find a framework that does graphics and learn the a p i, right?

But I can just hop into chatGPT and say, Hey, Make me a histogram for this audio, and it does it make me a three D histogram of this audio here and help me analyze it, and it just does it for you, which is pretty stunning. It's a game changer.

**Andrew:** Yeah, I, I've, I had the same experience, uh, recently. I was, uh, doing some AI stuff and I needed to use Python because everything's built on Python and I'm not a Python developer at all. And just the ability to kind of like, take my current knowledge of like, JavaScript and web programming and like use that to prompt the AI to give me the stuff back in Python is just

amazing.

Like, I was able to build a thing. That looks at a directory of images, pops each image up, and then lets me select a specific area of that image and like do it in a bunch of different ways. And I didn't even have to like go find out like how I would do that. It was just like, oh, you wanna use open cv? It has all of these cool things that it can do.

And it just popped out code and I was able to get running like immediately. It was, it was an amazing

**Eric:** Yeah. So that would be the, it was called the chat,GPT Code interpreter that does that for you. It has a built-in Python interpreter. It will run it, it'll write the Python code, run the Python code, get feedback from its console environment, try to fix bugs. If it sees that it wrote some bugs, it'll try to fix them automatically and so on.

So it has like an agent task model built into it. Um, so that's really cool.

**Justin:** Yeah, I think those iterative feedback loops are, are becoming the thing that is, you know, really powerful. So even if it's like wrong, if you can feed it into an agent and it can like, test itself and, you know, continue to refine, uh, that becomes super powerful with just like a few, just like a few, uh, you know, steps of automation.

**Eric:** Yeah. One thing that I like to do a lot is I like to ask it what tests should we run to make sure that this works properly and just have it write a bunch of unit tests and then I'll have it iterate until all the tests pass and, and that works pretty well.

**Andrew:** Yeah. Uh, copilot for tests is like the best use case. It's like you write the first assertion and then you hit enter. It's like, oh, yeah, I'll just tab until the end of the test and it knows exactly what I wanted.

**Eric:** Yeah. Or, or even just I, I very often I'll use chat t p t and I'll just say, Hey, write me some, write me unit tests for this function. I'll, I'll define a function and I won't even like spell it out. I'll just say, I wanna function that takes this input and produces this kind of output and let it infer the rest.

And I'll say, please figure out how many unit tests, what, what kinds of unit tests we need. Um, what edge cases did we miss? Like let it do one pass and then say, did we forget any, uh, any edge cases that we should check for? And then it'll probably add like two or three more tests and then just say, okay, now run this test suite against the code that we're testing.

**Andrew:** Right. Um, t d D on steroids right there. You don't even have to come up with the tests.

**Eric:** Yeah. So I call that AI driven development. So, and I have t d D in the process. So it's ai, T D D, basically.

#### [00:08:35] Ad

**Andrew:** We'd like to thank Raycast for sponsoring our podcast. Raycast is an app for Mac that's like spotlight, but way better. Besides being able to quickly open files, switch between apps, manage your windows, and even your schedule.

It also has a really cool react based a p I, And a whole extension store where you can find and distribute your own extensions.

**Justin:** A few ex extensions that I've been playing with this week are the color picker, which is a, a base one. This is actually written by Thomas, the c e o. So the color picker lets you just pick a color anywhere on the screen and, and save it via the extension or, uh, Organize your colors. Uh, it's a really handy app if you're just, you know, wanting to get a quick color value.

Another really interesting extension is just the brew extension. So if you've ever done brew, install some software. There's also a way that you can search home brew formulas, directly from Raycast. So just like two pretty quick, pretty simple integrations that are just quality and life improvements.

**Andrew:** You should also check out Raycast Pro. With Pro, you can take advantage of Raycast AI to do a whole bunch of cool things on your computer. It also gives you access to their cloud sync feature so you can keep your settings in sync across all your devices.

To learn more, you can visit raycast.com, or you can go check out episode 38 where we interview Thomas, the c e o about the product and why they built it. Do you wanna advertise with DevTools fm? Head over to DevTools fm slash sponsor.

#### [00:09:59] Intro to SudoLang

**Justin:** That's really cool. So one of the big things that can be, uh, challenging here is, is that, you know, we're, we're going from natural human language, which is very, very loose and very expressive to, uh, something that, you know, we wanna run on a computer to like do a specific purpose. And sometimes defining, you know, that pipeline of getting like solid, consistent results between natural language and, you know, the code output.

It can be a little bit un inconsistent sometimes. So that's one of the reasons why we got really excited about sudolang so would you like to describe sort of like what sudolang is and, and what problems it tries to solve?

**Eric:** Sure. Um, sudo lang is a psuedocode programming language that runs on top of AI language models like G PT four. So you can think ofGPT four as a sudolang code interpreter. And, um, one of the design goals of sudolang is, You don't need to provide the Sudo Lang spec for the AI to understand it. In other words, it knows about all of the features that sudolang has already because the features are really drawn from, um, the larger uni verse of what other programming languages have already done before.

So it's basically, uh, a curated collection of only the good parts of the best programming languages in the world. And we just kind of gather all those things into one specification. It does have a specification, um, that tells you about these features so that you understand how to use them and, and what's available.

Um, but. It doesn't need the specification to understand sudolang and run it. Um, so that's really cool. One of the great advantages of that over other languages, um, that other sudo languages where people define their own custom syntax and things like that, is that it saves you tokens because you don't have to tell it about the programming language.

For it to understand the programming language. It just does, it just infers it naturally. Um, which is super, super cool. Very useful. Um, there's a couple of things that you should understand about sudolang before you go and try to use it. One of them is that it is, uh, it's it uses a completely different paradigm from other languages that you've used before.

It's a constraint based programming language, and it was inspired by Ivan Sutherland's, uh, sketchpad Project, which was 1961 to 1963, and Ivan Sutherland was a genius. This is the man who basically invented direct screen interaction in the 1960s, right? The, the man who invented VR goggles in the late 1960s, later half of the 1960s.

Um, He invented a bunch of paradigms that are crucial and still very, very relevant today. One of those paradigms was constraint based programming in sketchpad. Uh, sketchpad was a graphical programming language, uh, and it was made to draw diagrams and things like that, but it could, it could do a lot more than just draw diagrams.

It could turn those diagrams into simulations that ran in the computer, so you could draw a circuit board and simulate the operation of the circuits, or you could draw a bridge and simulate the impact of weight and wind and things like that on that bridge for structural stability. Right. And, uh, so it was a programming language, but it was graphical.

You didn't write it in text. You put constraints in, the constraints were controlled by little switches. He would toggle a little switch. You would click on some lines and stuff like that in the diagram, lines and arcs and stuff in the diagram. Toggle a little switch and that switch would say, make all of these things mutually per perpendicular and it would just apply that constraint.

And then from that point on, that constraint is active. So if you change anything in that diagram, it reolves the constraints, right? So sudolang features dynamic constraints solvers automatically inferred by the AI so that you tell the AI how you want the program to behave in just natural language constraints, and then it automatically adjusts things like the values of variables and stuff like that in response. to changes in the program state. So it's pretty cool. It takes a little bit of getting used to. It's a completely different paradigm from what most people are used to programming in. And then there's one other major difference. It's not object oriented, it is interface oriented. And the distinction is really important.

An object has a concrete implementation with concrete implementation details. And interface is basically just a type definition. And anything can comply or not comply to that interface. But what's interesting about this is that you can take in interface and then create many, many different implementations of that in interface.

And in fact, with sudolang, you can do that across different programming languages. So for example, Uh, I've been working in smart contracts a lot, and I can take, um, and very often when you're working with smart contracts in web three, you have logic that has to be implemented on chain, but you've got a UI that you want to update maybe without waiting for the chain to respond to you.

You want to update it optimistically, which means you have to reproduce the logic that's in the smart contract in JavaScript. So you've got the same logic in two different programming languages. With sudolang, you can define the interface one time, transpile to both languages, and then you're in business.

So, so it's pretty cool. Um, that concept of, uh, language agnostic interface was first discussed in depth by Barbara Liskov in the 1970s when she was working on the clue programming language. And if you don't know who Barbara Liskov was, she's a touring award winning computer scientist who is the L in the, uh, in the, the liskov substitution principle.

Right. That's named after her. And basically what she was saying with the Liskov substitution principle was that, um, any two things that, uh, that use the same interface should be substitutable for each other in your program without breaking anything and often while the program is running.

**Justin:** It is really wild. So I've been reading this book, uh, H c I remix, which goes through some, some early pioneering papers. So is this like, as you're talking about this stuff, it's like I'm getting, you know, residuals from, uh, the, these. Is, uh, it's really cool to hear about how the, the sort of like history has inspired some of these decisions.

Um, and then like underneath the hood, so for the, um, the, the interfaces, the interface that's like translate translated between programming languages, so that's just done via the l l M, right? It's just like you have this in, uh, this, this interface and you're like basically building a prompt that says, given this, like translate it into

Python

or

whatever, right?

**Eric:** Yeah, so my favorite function in sudolang is the transpi function. And, um, basically you can, as a parameter, you can tell it the language you want to transpile to, but you can also do other things in that parameter space just with natural language constraint. So you can say any natural language constraint, it'll do it.

So you can say Transpile to JavaScript using next jss and use functional programming and it'll do all that. So it's, it's pretty fun.

**Andrew:** So like when, when does that translation happen? Like do I run a JavaScript service that like has the prompt and then like interacts with the L l M via the prompt, or does the l l M output code that I then commit to my repository?

**Eric:** So very often when I'm doing AI driven development, I want a chat interface. So I'm usually in chatGPT when I'm doing that kind of stuff. Um, in the future it may be, be, become, it may become way more agent based, in which case you'll orchestrate the agents from a language like JavaScript or Python and you'll have an agent loop and a framework that says, okay, this is the controller agent.

And the controller agent has the plan for the work to be done. And then delegates to other agents with specialties and those other agents with specialties, they're just the same AI engine, right? Getting past a different prompt that has instructions for a particular thing. Now you want those in separate prompts because there's how much, how much detail do you want me to go?

Do you want me to turn this into like a how to use AI to to write software kind of discussion? 'cause I can do that right. Um, but you can break up your prompt into lots of smaller prompts and then use the, um, use the language like JavaScript or Python to Orchestrate calling the various prompts. And you can have one controller prompt that says, okay, pass this prompt to this agent.

And, uh, and then just have JavaScript or Python do that for it. Just relay. So your JavaScript and Python stuff is just a relay between the AI agents and, uh, passing messages back and forth to them.

**Justin:** Yeah, we had, uh, we'd like talked a little bit in previous episodes, like very lightly on like Lang Chang and some of the tools that allow you to do sort of this agent based, uh, composition. And it, it's still, it's still always really fascinating to me, like how fast the space has evolved and like just how powerful these small primitives can, can become.

#### [00:19:29] What does it work for?

**Justin:** Um, so, so sort of like taking this back to, to sudolang a little bit, um, so how would someone just get started using sudolang and, and then specifically what kind of problems do you think that it su that's like really, really well suited for?

**Eric:** Okay, so let's talk about the problems first and then I'll dive into like how to get started. Right. So the problems that it's not well suited for are just simple question and answer kinds of things. Like if you just want to have a chat with your AI language model, just go and use natural language. It's fine if you want to, um, if you want the AI language model to basically run a program, which means keep track of state, that can change over time.

Um, use specific interfaces with specific shapes and specific types. Right. sudolang is gonna help you a lot there. Um, Sudo Lang's, uh, interface system works really well for controlling the shape of its output and stuff like that. Its constraints and constraint based system makes it so that you can instruct it pretty easily to always deliver a specific kind of response.

For example, I frequently prompt it to always give me, uh, always give me its answers in YAML format and then that YAML gets interpreted by JavaScript or Python and um, and that is kind of hard to do just using natural language, but it's much, much easier with pseudo and some constraints. And by the way, if you're, if you have tried to do that, you probably know it's not as easy as I just made it sound to get it to just output YAML or JSON and only YAML and JSON without any explanation and all that stuff.

Um, constraints allow you to easily direct it to do that, uh, or more easily. But even with constraints and, and interfaces, very often you'll have to repeat your instructions in different ways a couple of times to make sure that it's really gonna only do the JSON output or only the YAML output. But it's worth doing because, um, if you don't do that right, you'll get a higher rate of failures, which means you'll have to retry requests, which means you're wasting tokens and wasting money.

'cause inference is expensive still. Um, so the kinds of problems that you want to address with it are the kinds where you have very specific IO requirements or you have, uh, evolving state that you want to keep track of. And, um, I , I want to just kind of point out that sudolang, um, just using code or sudo code to prompt the AI language model has a couple of interesting effects.

Um, The AI naturally thinks about, um, it, it, it, it sees the connotation of the context that you give it and relates that to its understanding of the world. Its mental world model. A lot of people underestimate ais and don't even realize they have these, but they have semantic world models and there's associations that get triggered in different contexts.

And when it sees code, one of the associations gets that, gets triggered is this thing looks like an interface. This thing looks like a data structure or a type that I need to pay attention to. And there are keys, properties on that type, that data structure and type, which means I need to pay attention to those keys and make sure that I'm following the logic of updating that as I'm thinking through this problem.

So just seeing an interface triggers that kind of response in it. It's saying I need to keep track of these variables. And then, um, seeing specifically curly braces triggers kind of a code mode of thinking in the ai. And what I mean by that is when you're talking in natural language, natural language tends to be kind of informal and you kind of say what you think off the top of your head instead of thinking things through very carefully.

But seeing curly braces, and in particular this works better with languages like JavaScript or languages that have curly braces than languages that don't like Python. It is very good at writing Python code and stuff like that. But if you want it to understand a problem and think about it as a problem, the, uh, as like a technical problem, put curly braces in your syntax and that turns on like some a little magic mode in the ai, that magic mode makes it 10 to 15% more likely to return correct answers to your prompts.

Is that something that you like that is in the sudolang prompt, or is that just like some property of LLMs that you just happen to

**Andrew:** discover and

it helps for

sudolang

**Eric:** That is a property of LLMs that happen to be discovered by me and some other researchers who have been looking into prompting AI language models and, and how to get good results from them. So there's a whole field, uh, called prompt engineering, uh, where there's like a bunch of nerds like me that just sit, you're prompting AI all day and recording results and figuring out what works and what's, what doesn't.

I've been doing that every day since 2020, the summer of 2020 whenGPT three first came out. So, um, maybe this is a good time to address the genesis of sudolang a little bit. Right. Um, So I was doing that, uh, prompting every day, playing with code. In particular, I was very interested in the application of using AI language models to help build code because I've always wanted to like replicate myself so I could do more projects more quickly and take on more, um, more challenging tasks.

And, um, one way I thought of doing that was just kind of, maybe I can just encode a lot of this stuff that I know about programming into, uh, some prompts and say, okay, this particular thing is gonna be a React component, so give it some instructions related to writing good react code. Right? So I've been playing with that since about 2020 and really kind of digging into that.

And then I saw, um, I saw, uh, my friend Jake Brookman, um, post, uh, a tweet that he had created his own sudolang code programming language called Jargon. And he put it on GitHub and I was like, Now, I've been doing this for a long time. I've learned a lot about what works and what doesn't. When I'm prompting AI language models with code and for code using sudo code, uh, to kind of spell out what I want, I should record some of the stuff that I've learned and put us put, make it a language specification.

So that's how that came to be. That was March of this year, I think. And, um, and it was so successful and like formalizing that language and starting to use that particular language instead of like ad hoc with every new prompt. Um, it was so successful. It was so good that I've now, uh, I do most, not most close to a hundred percent of all my programming starts with a pseudo lang prompt and then, uh, turns into JavaScript or Python or, or, um, you know, solidity smart contract code or something like that.

Uh, I've, I done it with c it works with any language basically.

**Justin:** So are you using pseudo lang as sort of the, the structure of the scaffolding to get started with a larger program? So you're sort of like describing your, your. Domain or sort of like exactly kind of the interfaces that you want to see or whatever. And then it's like doing the transplantation and everything and, and sort of setting you up for this other program.

Is that

sort of your workflow or what does it look like when you're using it?

**Eric:** You can think of sudolang as having three different workflows, right? Um, one of them is to produce a program that is designed to run on the la large language model as like a chat interactive chat program. So for example, um, things like community moderators for chat rooms or bots that, that are supposed to interact with users.

Uh, question and answer bots for websites, those kinds of things. Um, those things are designed for interactive sessions that evolve over time and have a whole conversation history and sudolang is really, really good at doing those things. Um, there's a program, there's an example, pseudo lang program called AI Friend that, um, that will guide you through the creation of a prompt for a chat bot and it'll create the chat bot prompt for you based on your specifications.

And then you can just like, paste that into and character.ai or something like that. And it just works. Um, works really well. Um, and then there's another mode that I call, uh, AI driven Development or AITDD And in that mode, I'm using the AI to write programs that will run in JavaScript or Solidity or Python or c or whatever.

And uh, so that's an AI driven development process, and I've got a whole big process around that, that that goes from, uh, story mapping, user stories, figuring out your user stories and tasks and stuff like that, and organizing that and figuring out priorities, what to do first and, and, um, writing the documentation.

We do like a Read Me Driven development process, which means we write documentation for the all the interfaces before we start implementing the interfaces, and then our teams can work in parallel. Um, now imagine that you do the same thing, except all of that stuff is written by the ai, including the documentation, including the requirements and all that stuff.

And then the AI delegates those tasks to other ai and, and they do the things like writing. So we have a special module for writing redux to handle client side state. We have a special module for writing, um, react components and special module for writing smart contracts and solidity and so on. And it's just like each one of those has a particular specialty and the AI drives that process.

And, uh, that one we're working into more of, uh, an agent framework and hopefully in the future, um, that will become, um, a very, very important workflow. It's a little bit early for agent frameworks because they're. They still require a lot of handholding. They still make lots of mistakes. Uh, language models hallucinate a lot.

And, um, that's something to account for. And they can also get stuck. And, and there's lots of challenges with context and attention windows and stuff like that, that I could go into a lot of technical detail about. But I probably won't bore you right now. Um, but if you're curious, reach out and I can teach you all about that.

Um, and then, um, another mode is so, so, um, what I just described, I call meta programming, where you write programs that write programs, right? And then, um, the last mode is just piling where you prompt the AI with, uh, pseudo code that is designed to be trans compiled into another language. And you just transpile that Sudo Lang into JavaScript or Python or whatever.

So basically you're writing, you're just writing the program that you would've written anyway, but you write it in pseudo code instead of your target language, and then it transpiles automatically. And um, that's really good for things like I was telling you about, where you have logic in both JavaScript and, uh, smart contract programming language and you want to transpile it to both places and you only wanna write the thing once.

But it's also really good for just writing raw JavaScript because I can write like a five line JavaScript to React, or a five line Sudo Lang react component that'll expand into 60 lines of JavaScript. And so I, it can take like a few minutes and do something that would've taken me 20 or 30 minutes in raw JavaScript.

#### [00:31:05] Thinking in SudoLang

**Andrew:** That's, that's all super interesting, uh, like. It's like, uh, here at Descript we have, uh, we're integrating AI into like a chat bar and it's supposed to like, interact with our document model for like a project. And I think one of the, the big problems we've had is getting like, good input and output and like making it, uh, like, I dunno, deterministic.

So like d So how, how do you like, deal with that? Because like when I, when I'm talking to like non-tech people about ai, I always try to frame AI very specifically that like, classic programming we're used to being able to get to basically zero bugs, like classic programming. You have an input, you get an output.

If you find a bad output, you can change the code, get, get the right output eventually. AI inherently isn't like this one-to-one mapping. It's like this like one to N mapping. So how do you like deal with that in your code in like shipping applications built on top of ai?

**Eric:** So there's a couple of things that I do. Number one, I write specialist programs that'll do a particular thing really, really well in suiting. So programs that write programs. So in, in those programs, you can give it really good constraints around the style of code to use, um, and stuff like that. So it's if, if you do it that way and you do your interfaces right, for example, you can make it always use functional styles and always use very minimal small functions and compose those together to form the application.

And then, uh, when you do that, when you keep the functions really short, it tends to produce. Pretty much the same function definitions every time, which is cool, right? Um, but that's not the only way to be. And maybe thinking about it as deterministic out code output is the goal, is the wrong approach, the right approach?

Is it determin Deterministically passes all these tests every time, right? And, um, it won't do that for a single run. Um, so sometimes it's gonna go off track, it's gonna make mistakes. But if you're running, if you first have it, write a test suite, right? And then run that test suite on the code that that outputs every time, then you can make sure that re requirements are all met.

So that's where the T and the A I T D D comes from. And I, I often leave the T out because in, in my mind, if the T isn't there, if the testing isn't there, then you're not doing software engineering. You're, I don't know what you're doing. Legacy. weird I don't know what you're doing, but it's not engineering, right?

Engineering implies that the code that you write, you prove that it works, right? You prove that it works. You don't just like rely on luck, you know, roll the dice and like, and even if you're not using ai, humans have the same kind of mental processes that AI have. Um, AI is based on human brains and how they work, right?

The, the modern deep learning ai, um, it's neural networks and a neural network is just like this thing that registers inputs and does some summing and produces some output signal. Your brain is made a bunch of, a bunch of those. A neural network is just a big multi-layer, um, a lots and lots of arrays of parameters, and each parameter is just a number.

And those numbers are just doing matrix multiplication to produce the output. So it's taking a bunch of inputs, summing them, running a little soft max function on producing it an output, and that that sum from the inputs into that output. That's how your neurons work essentially, right? I'm glossing over a whole bunch of differences with like the underlying substrate, right?

Like. It's not wet, it doesn't require blood. Right?

but but other than that, like the basic idea is the same, right? We take a bunch of signals, we send them together, we produce an output, which means that a lot of the things, a lot of the problems that humans have, like lapses in working memory and attention and, and forgetting things.

AI can do the same thing and have the same kinds of mistakes. So in other words, if you use the same kinds of quality processes that you use with humans, code reviews, unit tests, things like that, to ensure that the quality bar is met, then you can get similar results with ai. So just think about your ai, like another human collaborator that you have to watch.

'cause they might make mistakes,

**Justin:** this is why I've always appreciated the um, The sort of language around collaboration with, with chatbots and anytime we're, you know, using LMS to, to sort of write code. It's not like a, a magic machine that we, we give it a very bare base English specification and it like, comes out with this magical code that always works and is bug free.

Um, it, it really is. It's like, you know, getting, uh, like, I don't know, you know, it's like getting someone who's like really well read in the documentation, but like maybe isn't always paying the closest attention to write the code. And it's like, you know, sometimes it's like on course and it can be off.

But yeah, like things like generating tests I think are, are an incredible strategy and especially because you can really think about like, what is the intent, the intent of the thing before, you know, it's really written. Like especially you're, you're thinking about interfaces and you're thinking about tests before you're thinking about actual implementation and like,

you know,

that leads to like a good

model.

**Eric:** Yeah, exactly. That's one of the things that I love about sudolang is like I'm only thinking about the interfaces pretty much. I'm only thinking about the interfaces. What do I want it to do? Uh, what state do I need to keep track of? And then all the implementation details are just handled for me. And I like that because when in, in the end, it's the interfaces that matter.

So, sudolang is not object oriented. It's interface oriented, right? Uh, it's, and, and you don't write functions. You write, um, you basically say if you wanted to write a function, you just name the function and it writes it for you. It fills in the missing details for you. It infers, right? So, keys to being successful with Sudo Lang first, go the Sudo Lang source code repo on GitHub at the bottom of the Read Me there are, there's like getting started guides with like links to a bunch of articles on how to write it and, and what Sudo Lang is and stuff like that.

Uh, and that'll get you started with it, right? Um, and then when you're using it, remember that the AI is an intelligent thing and it can infer a lot of things and you need to need, you need to lean into that inference. In fact, if you try to overs specify, you'll make it perform worse because you fill up the context window and when you fill up the context window there, you don't have perfect attention.

The AI can't pay perfect attention to everything in the context window. So even though, uh,GPT four has like 8,000 token context, you can really only use about 2000 of those tokens and still get good attention across that context. So, um, and that's because it has a limited number of attention heads and attention heads are really expensive to scale.

So, um, I don't know, uh, the particular details of how many attention heads is inGPT four, but I, I can guess it's probably around a thousand, 1,024 ish, right? Or 1,040, somewhere in there. Um, the, um, llama two is open source and you can see how many attention heads it has. It has a 2000 token context window, and I think 32 attention heads.

So do the math. It, it's gotta spread that attention across all of those tokens and it can't be, it can't do it perfectly. So, um, yeah, lean on inference. Don't type everything, don't overs, specify, uh, and overs specifying would be defeating the point anyway. What you wanna do is less work, not more work.

**Andrew:** So when you're writing sudo lang, you should like really lean into constraints. Like you, you set up a function and you say like, these are the things that I want to be true about it. Everything else is up to you,GPT.

**Eric:** Yeah, basically, or even less, right? No constraints, just the function name. It can usually figure out the, the rest based on context. So, uh, only right constraints when it's doing something wrong and you need to correct it, pretty much

you need to guide its output, uh, to more, to a more successful output.

That's when you add constraints.

**Justin:** one of the, the interesting things when I was like, going through the sudolang documentation and everything, and, and you, you'd mentioned this, uh, a little bit earlier, but, um, you as, as, like, Sudo Lang could be useful for like, certain chat applications or certain, like, structure chat applications.

So you have this, uh, commands feature, uh, which is, you know, if, if folks have used a Discord bot or, or something like that, this is like a slash command or in Slack or whatever. This is a very common, uh, interface. Um, so it, it, it's just kind of interesting to see that bundled up in, together in this sort of like sudolang specification.

Uh, what are, like, what are commands and, and what was sort of the, the impetus in adding that into the specification.

**Eric:** So, um, very often I'll be using, if I'm doing something like programs that write programs, then I very often I will need multiple phases of prompts to get the context into the, into the language model for everything that it needs to know to do a good job of its output. And, uh, for me, the most natural way to do that was slash commands and, and just telling it about those slash commands, um, it, first of all, it recognizes them instantly.

It knows exactly what they are without any prompting. Um, and if you just add a slash command help, right? You don't even tell it what help is supposed to do, it'll just list those commands for you.

**Justin:** So it just, it, I, I had the idea, I tried it out, it worked. First time I was like, okay, this is going into spec.

**Eric:** This is awesome. And I use them all the time.

**Andrew:** It. Yeah. It seems like the dream way to write a C L I like you just like specify kind of the shape of what it does, some commands it might have, and just a thing does it all for me. Sounds like a dream.

**Eric:** Yeah. So one interesting thing, when I was working on building the agent Orchestrator from JavaScript, I was like, okay, I want to be able to edit my sudolang prompts and just in sudolang format and just a natural text file. Right? Um, but then I wanna also be able to import those prompts as modules in JavaScript.

So I had it write a C l I, um, I created a Sudo Lang interface to. To that specified a c l I to do that conversion for me automatically. And it did that and it works great. And, um, then I went and, and, uh, put it in my, uh, package, json file. I have a watch script that just watches my prompts directories and automatically converts them into importable JavaScript modules.

So now all my prompts are importable JavaScript, which is great.

**Justin:** That's really cool.

#### [00:42:18] Future of Coding with A

**Andrew:** Yeah. So I wanna, I want to dig into the language a little more. So we've said sudol code and sudo a lot, but how sudo is sudo, like, how fake can my code be, like in a, a regular programming language? Like I have a syntax error, the program doesn't work. Can something like sudolang l like just kind of not care about syntax

errors?

**Eric:** Yeah, it usually doesn't have any problem with syntax errors. It'll just keep on going. It'll do the right thing. You probably won't even notice the errors there. Most of the time, like I'll make, I'll make mistakes in pseudo laying all the time. Little syntax errors and stuff. I'll forget like a trailing brace or something, and it just does the right thing anyway.

Um, I don't like to have those because, um, for me it just feels, it just feels wrong, uh, to have mistakes like that, typos and stuff, but it handles them like a champ most of the

time.

**Andrew:** Uh, like, so that brings me kind of like the next logical point is like, most languages have an LS P, they have syntax highlighting. Does sudolang have something similar?

**Eric:** sudolang has sort of broken syntax highlighting, and the reason for that is because, um, sudolang uses natural language constraints. And, uh, it leans a lot on natural language. The, um, sling program, the structure is, it starts out with a preamble, which is the program title. Um, and then it says like, act as and some role for the AI to play.

And then a little bit more context there. All that is in natural language. And then it starts dropping into, um, supporting, co supporting interfaces and functions for your main interface. And then at the bottom is your main interface, and then like a one line, uh, starting point or initializer. And for me, usually I just type welcome with some parentheses after it.

So it'll call this function called Welcome that I, I never defined anywhere. And then it'll just tell you what it is and show you the commands usually. Because of all the leaning on natural language, which, which doesn't have good well-structured syntax rules, um, it, it's really hard to make a language system that properly understands sudolang without also making that language system a large language model that infers it and then inserts highlighting for you, uh, which is definitely going to be possible.

But right now I think it's probably cost prohibitive to, to be doing that on every keystroke, sending it your whole source code for that file, um, as you're trying to change code and stuff like that. So I think we'll have to wait for technology to advance a little bit more before we get really rich, um, interactions.

But once we do get those, They're gonna blow away every other code IntelliSense thing you've ever seen, it's gonna blow the doors off of them all.

So the future's gonna be really bright. Right now you kind of have to live almost without syntax highlighting. You basically use some, um, some really simple syntax highlighting that just like matches the braces, and at least you can see if your braces are matching.

**Justin:** yeah, it'll be really interesting to see like the future, especially like AI integration for stuff. So if you could do things like backfill or, or like, uh, syntax, highlight this, like code for me or whatever, because you know, especially as we get into looser specifications, Um, things that rely more on natural text that you need an L l M anyway.

Like, you know, like you were saying, it's just like there is a really interesting opportunity for like AI powered tools here for like generating, I don't know, all kinds of stuff, like syntax highlighting or like a code hints you could imagine. It's like, oh, I'm hovering over this thing and I just feed it to, uh, an L L M and just like automatically populate the i d e content.

**Eric:** Yeah. I, I just wanna touch on like the future where this is going. Um, I think in the not so distant future, we are gonna see AI tooling that will, um, be completely aware of your entire code base, your git your branches, all of that stuff.

And it will be able to, um, look at your code, look at a problem that it's supposed to solve, work on that problem, and then open pull requests directly without any human interaction whatsoever. And I think that eventually we'll become more like creative directors for our programs than just. You know, for lack of a better word, just like cogs in a code machine, right?

Um, let the AI be the cogs in the code machine. Let them work on the code, and, and we can focus on like the higher level problems. Like does this solve the needs of the users? And, uh, I think that in the future there will be like, uh, the capability for any, to anybody to say, to go to an AI language model or, or, or, um, an agent pipeline and say, um, build me something that's kind of inspired by this other thing, but uh, I wanna do these things instead.

And you can kind of remix anything out there, including software, including software applications. So I think the future is gonna be like a lot more people. Uh, so right now the, there's kind of this inherent gatekeeping in software engineering where you have to go and you have to learn just a mountain of stuff before you can be productive and write apps.

And in the future, I think it's gonna be more like if you have a good idea and you've got some AI tooling, you can build apps and, uh, anybody's gonna be able to do it. And then I can't wait for that day because there's a lot of creative people out there that would be building really amazing stuff if they just understood code.

Right. Um, So I'm, I'm really excited for not just like the future of AI assisted code, but the future of AI assisted software development in general and beyond software. Lots of other generative AI kinds of things, graphics, videos, um, you know, games, all kinds of things. It doesn't have to be just software.

And, uh, so for me, like this is the most important technology, uh, technology revolution in the history of humanity. I think this is more impactful than the creation of the computer because the computer up to now has been limited in what it can do by what can you very precisely instructed to do. And that limit has just been lifted.

And this is gonna be a transformation that's gonna change every industry. And, um, and, and it's impossible to overstate the impact that it's gonna have.

**Andrew:** Yeah, we talk about lowering barriers a lot on the podcast here, and it's usually like the, the scale of the barriers being lowered is, is a lot smaller. It's like, oh, we made it easier for multiplayer apps to happen, but like AI is like the ultimate barrier. Lower, lower. Like no matter the field, if it's a creative field or now even like a software field, it makes it so that like the skill doesn't matter.

It's like the human creativity does. And it's such a scary and exciting thought all at the same time that my skills no longer matter, my creativity does. And it, it's an interesting future. We're walking towards.

**Eric:** Yeah. I think to invest in that future, you need to invest in your communication skills, right? Your ability to translate the cool ideas you have in your head into, uh, something that. An AI language model can understand. And I think we've already seen this with the invention of things like Mid Journey and Adobe Firefly and stuff like that in the graphics world, right?

Um, it used to be you had to go to art school and study how to draw lines and like you'd draw million circles, right? And learn to craft your drawing skills. And now you can just go to Mid Journey or, or Adobe Fire Firefly, like even selecting sub. Part of an image and say, uh, replace this t-shirt logo with like the superman emblem or something like that.

And it just does it, and it does it better than I could do it. You know, it doesn't, does it better than most artists could do it. It does it to a really high degree and even a very high degree of photorealism. And there's gonna be a point where you won't be able to tell whether a human generated something or an AI generated it, or whether something is a photograph or something is generated by ai.

And the same thing is happening to code eventually. Um, eventually it's gonna be the same thing with code. You're gonna be able to, you're not gonna be able to tell did a code write, did, did an AI write this code or did a human write this code? And, um, yeah. So it's democratizing everything. And I think this is really important because right now, you know, talent is evenly distributed across the world.

Like everybody everywhere has some. Talent or some great, uh, level of creativity and, and, but opportunity isn't right. Those people don't have access to the same educational resources, the same kinds of, uh, money and opportunities and stuff like that. And I think one of the great things about AI is that it's completely obliterating those barriers and obstacles.

If you have access to an, the AI model, right? You will be able to, uh, access these resources. And I think that that's super important.

**Justin:** It's a really fun future for sure. Uh, And, and a little bit scary. I think. Uh, it is a little, there's a lot of optimism, but a little bit of worry about like, you know, displacement of, you know, I dunno.

**Eric:** Yeah, well, we're gonna have to adjust, like what skills, uh, are we focusing on and, and how do we, how do we even work these days? Right? But if you think about it, the, the challenge for the challenge hasn't really changed very much for people that are coming fresh out of college, because it used to be, like in the 1990s, early two thousands, you come fresh out of college, they've taught you a bunch of Java and like nobody's, well, there are people using Java.

Let me, don't, don't get me wrong, but. Nobody's using Java the way it's taught in colleges, right? It's just doesn't happen in the industry, right? So you go with a whole bunch of skills that the universities banged into your head, like, inherit from this, and then inherit from that, blah, blah, blah. And then nobody does that, right?

Everybody in the industry uses composition over inheritance. They're focusing on functional programming. They added link to C Sharp they added like lambdas to Java, like all this stuff, right? Nobody codes in the style that they teach, that that, that they were teaching in college. So people come out of college and they find out that a lot of what they learned is not useful in the workplace.

And and colleges also have a tendency to focus on a lot of the low level details. Like, here's how a computer chip works, here's how binary works, right? Then you get out in the real world and nobody writes code in binary, right? Nobody, even systems programmers. Use like assemblers and, and stuff like that.

And they don't write directly in binary. They don't like calculate the difference between the binary digits and the hex digits and all that. Nobody does that, right? It's useful conceptually, but it's not useful. Um, it's, it's not gonna make you a better programmer, um, unless you're writing like really, really low level code.

It's just, it just doesn't matter very much these days. Um, but in the early days of computer science, it was like the only thing that mattered because you were always dealing directly with those kinds of things and then the university systems just didn't keep up. So, um, what, what you have to do when you're coming outta college now is you have to realize like, okay, all this computer science literature that I studied, right, all this computer science knowledge that I, that I learned, um, doesn't really matter very much like knowing how to implement.

Um, A binary tree. Right. And, and walk it in Java is not going to do anything for my job. Right. But, but here's the thing, like a lot of the college kids, they're in chat,GPT, they're using chatGPT help them with their homework. And those skills are the skills that they're gonna need when they come outta college.

So, so I think that's kind of ironic, but a lot of people are already gearing up on AI and learning how to do AI driven development and learning how to like, go and prompt an AI and say, Hey, write me this documentation that my, my teacher wants me to turn in next Friday. So ironically, like cheating on your college homework is probably the best thing you can do to prepare for your career. It's gonna be a big transition, but, um, think, uh, do we have much more time to talk

about

AI language models in

general?

**Andrew:** Oh yeah, I'm, I'm down to talk.

**Eric:** So, uh, there's a concept that I want to touch on. Um, I think that a lot of people are underestimating AI language models in a lot of ways. Like, um, so the AI researchers who were talking the most about this a few years ago whenGPT three out and, and, and chatGPT. Now a lot of researchers who are chiming in on this.

Our researchers who've been beaten down by three or four decades of failures in language models and getting language models to understand natural language. So they come with this burden of, of failures, and I know this because I'm one of them, right? I started working with AI language models when I was a kid.

I was a teenager, so I've been doing it for decades too, and I totally understand where they're coming from, but. They're, they're using that pattern matching and they're making assumptions about today's language models that just are not true and some of those assumptions. I I want to break down some misconceptions right now.

So, um, first of all, an AI language model does understand you. They're not stochastic parrots, right? They do understand what you're saying and what I mean by that is you can describe a problem to an AI language model. It can explain the problem back to you in its own words, answer open-end ended questions about it.

Then it can write a working solution to the problem in code or in some kind of design. And then it can explain to you in detail how that solution works. Answer open-ended questions about either the problem or the solution, right? If any human could do all of that, we would have absolutely no doubt. The human understood the problem.

They understand the assignment, right? Um, most of the time your AI language model understands you. They understand the context. So another thing that people have a misconception about is they think that the ai, uh, doesn't know information about how the world works. In other words, they think that an AI doesn't have a mental model of the world, that maps to the real world like a human does, right?

Um, that is also wrong. Um, and what I mean by that, is AI's, as they're learning, as their neural network is being trained with back propagation. This is not just collecting a bunch of statistics and making lookup tables. It is building a semantic graph, a semantic map of the world. And what I mean by semantic, semantic is just the fancy word for meaning, right?

So it's building a map of the meaning of words and the meaning of, uh, you know, basically tokens or objects in the world. Right. Um, just like we use, uh, symbols to understand the world and map it to meanings, we, so for example, if I tell you a word and there's like synonyms to that word, you will be able to give me a syn synonym usually if, if one exists right, you'll be able to spit back a synonym at me because you have a latent.

Mapping of the semantics of that word in your brain. AI language models also have those latent mappings of semantics. They learn semantics and they have, uh, they have something called an attention mechanism. And that attention mechanism, basically it's tuning into the input so far in the prompt and it's saying this word relates to this word in this particular way.

And it learns through back propagation and training to find features in the language and features of the world. Extract features of the world from that language. And it uses that to build mental models of the world. And you can prove that to yourself by running some experiments in chatGPT. You can go and say, generate me 20, uh, random strings with random, jumbled characters, right?

And then generate 20 random numbers, right? Zip them together. And then tell me, uh, and then after that, right? Let it do that first and then prompt it again and say, now imagine those random strings correspond to materials and those random numbers correspond to density. And assume that all of these things are equal sized spheres.

Same volume spheres. Now put two spheres on a scale and tell me which one, which one drops on the scale. Right. And it can tell you because it knows what gravity is, and it knows that gravity is related to density and you know, has a mental model of physics. And it's mental model of physics, by the way, is richer than mine.

It could build a better physics engine than I can in source code. So, um, they have mental models of the world. Um, and one more thing. AI researchers had this conception that, um, You could not train in AI on text alone. And you know, to a degree that's true, but they, they assumed that there was gonna be a lot of missing information because humans assume that you have common sense when they're talking to you.

So they just don't say a lot of what would need to be said to a computer for the computer to understand. But remember that AI language models have been trained basically on the entire freaking internet, right? They've learned a lot of things about a lot of things, and that gives them common sense. And you can prove that to yourself by going into chatGPT and you say something like, um, Imagine you hear the words, table three needs a coffee refill.

Look over at table three and tell me what you see. And it will describe to you people sitting at that table, not just like a table and coffee, right? Like people sitting at the table and it knows that the people want to drink the coffee, not the table tables don't drink coffee, right? And it knows that those people are probably engaged in conversation and maybe they've got some other like snacks sitting on plates and stuff like that.

And, and it can come up with this entire scenario. It knows that numbered tables are often associated with cafes or restaurants and things like that. So it correctly infers the setting and all that information. So the missing information problem doesn't exist in large language models. It did exist in small language models, but it doesn't exist in large ones.

Uh, not to the degree that a lot of researchers thought. Um, yeah, I could keep on going. I could write a book on this.

**Andrew:** Well, it's, it's all very exciting and scary all at the same time. I'm, I'm excited to see where coding goes, uh, even though I put my last 10 years into it. Um, uh, but with that, let's, uh, transition to tool tips

#### [01:01:44] Tooltips

**Andrew:** Okay, so my first tool tip of the day is a new code editor called Cursor. Uh, cursor is a fork of VS code, which that's, that's a great way to start. Uh, an editor, just fork one that everybody loves already, but it's an editor with AI as like the main focus. You might be asking, oh, I have chat.GPT, I haveGPT X, uh, copilot X.

Uh, how is this different? Uh, it's probably not all that different, but it's here and you can use it now. Uh, and it has some really nice features, uh, for like generating code. You can have the whole like, talk with code thing. But what I've really liked is the way you edit existing code. You just highlight some code, hit command K, you get to write a prompt in there, it thinks for a little bit, and then it'll, uh, change your code right in the editor and you can accept and deny the changes.

It's a really nice experience and like it doesn't change too much code. So if you're like, oh, Just add some comments to this thing. It'll go through and not change any of the code, and I'll just add a bunch of comments. Uh, and another cool feature is it works off of your own, uh,GPT A, uh, a p i key. So you can basically just download this and you already have aGPT four access load your a p i key in there and start using it.

So if you've been u if you've been looking for a code editor that's more AI focused, I would definitely give cursor a look.

Have you used Cursor, Eric?

**Eric:** I have heard of it, but I have not tried it yet. I have the um, vs code, um, they have like a preview version, insider's edition. I have that with a chat built into the sidebar and stuff like that. So, um,

I

haven't

tried it, but

**Andrew:** Yeah. I, I, I hope they steal the highlight

code. Command K

do stuff.

**Eric:** they do have it. I do have highlight code. You highlight the code and then uh, you pop open the chat window and just tell it to do something and, and,

it

can,

do that.

**Andrew:** Next up we have, uh, NIF, N T F Y. Nfty

**Justin:** uh, I like small, simple tools. Uh, it's always a thing that I come back to. And, uh, this nfty tool, it's just a notification service that you can use over the shell.

So you can just literally make a curl call, uh, to nifty and it'll send a push notification to your phone. And I mean, that's it. And it's awesome. Uh, I think it's really, really great to sort of pair with other small, like shells, scripts and stuff. Um, So I use a hammer spoon on Mac, which is just a lua like scripting environment or whatever.

And it's really easy to make a call to Nifty, to like send a notification, you know, when a script completes or something. So just a really cool service. Uh, you can kind of host it your own yourself, or they have a paid service if you want to use theirs for like $3 a month or something. Um, really simple, really good utility

**Andrew:** It's pretty cool. I could see how this would be useful in the home automation space. Uh, I looked into doing something similar, uh, back the last time I tried home automation and I had to set up and pay for so many different things. I was just like, I'm gonna just use my Discord server. So, uh, I'll probably take a look next time I try to automate my home.

Next up we have daily bot.

**Eric:** Yeah, uh, daily Bot is fun. Um, it's basically if you, if you use Slack to communicate with your team, it's just a really great way to replace your, like, video or standup meetings, um, in the morning. And it's just like a two minute, like, interview with this little bot, and then it creates like really cool reports for, uh, what everybody's working on and their status and stuff like that.

So, um, it's just a fun way to communicate and, and let your whole team know what you're working on at the moment. Um, it's my favorite check-in kind of tool.

**Andrew:** Yeah, that's, that is cool. Um, next up we have view transitions, uh, specifically the Astro implementation of view transitions.

**Justin:** Yeah, so Astro 3.0 just dropped recently and, uh, they have built in support for V Transitions. If you haven't read up on V Transitions, it's a relatively new browser, uh, capability. So you can make these really nice transitions without relying over overly much on JavaScript. Um, so it, it, it makes it possible for like traditional server side rendered apps to do these more fancy spa-like transitions.

Um, it's really cool spelt just dropped, uh, similar support and other frameworks are sort of following up, but, uh, I really thought Astros uh, version of this is really well done and their docs are excellent. So even if you just wanna learn about view, transitions are really good to just check out their docs.

**Andrew:** Yeah, this is a feature that I've been seeing on Twitter just constantly, and it looks so, so cool and so powerful. I haven't dug it all into it yet, but, uh, I'm, I'm really excited to see where I can add this into the, the things I make.

Okay, now we have Sonar Cloud.

**Eric:** Yeah, so I've, I've been kind of using Sonar for a while now, but, uh, sonar Cloud is a hosted version of it. It, it provides, uh, source code quality visibility into your code base. There's a bunch of other tools like it, but, um, I just really like how easy it was to get started with Sonar Cloud and start seeing.

Um, the, the richness of their quality checks, uh, are really good. I like the idea of continuous quality, where, um, a lot of the other tools, you install them and then it shows you like a million issues that you need to fix. And, uh, sonar Cloud kind of approaches it. Like, no, let's just continuously make sure that as you add new code, it's adhering to quality, good quality standards.

And as you're changing code, it's adhering to good quality standards, which was how I liked to upgrade my code base anyway, just kind of iteratively instead of like shutting down development for like three months while you go and update all your legacy code. So I think that they had a really good thinking, uh, really clear thought around the UIs and the workflows and the designs and everything around Sonar Cloud.

So check it out. It's kind of cool.

**Andrew:** Yeah, that's cool. We've covered a, a tool on here a few times called Betterer, where it's like the same idea of like your current code's kind of fine. Just don't, don't make it worse. So, uh, cool approach for managing a repo for sure.

and then last tool tip of the day. Uh, I think This Which one do you wanna do, Eric?

**Eric:** So the advanced data analysis, probably the best way to do it is just to go to chatGPT and show it

**Andrew:**

**Eric:** cause it's, it's really cool. So it's a feature of chatGPT that I, it's a beta feature, which means you need to go into your chat,GPT settings, uh, the three little dots next to your name at the bottom.

Click on settings in beta and then turn on the under beta features turn on advanced data analysis. It used to be called code interpreter, but basically it's just the Python it code interpreter baked into your chat,GPT. And, uh, what that means is you get access to an agent. An agent loop, which means it can run code.

Look at the output. If it made a mistake, it can try again and keep on iterating on the problem that you give it. And it's so good at that, that I've had it write basically entire books in like a few hours. Like it's pretty great. Um, so it's a very powerful, very capable thing that you should check out.

And, uh, if you wanna learn how to use it, um, go over to dev anywhere.io and sign up for our AI Whisperer track.

**Andrew:** Sweet. I think that, uh, wraps it up for tool tips this week. Um, thanks for coming on, Eric. This was, uh, this is a conversation I'm gonna have to sit with for a while to like fully understand the things, and I'm very excited to like, try out sudolang I don't know where I'll try it out yet, but it seems like a very novel concept.

**Eric:** Yeah, Just jump in and start playing with it. Go to the bottom of the sudolang repo. Read me, and then there's a bunch of like links to little articles and stuff to learn about sudolang and the concepts like interface oriented programming and constraint based programming and stuff. And, uh, pick it up and just

play with it.

**Justin:** Yeah. Uh, I'd just like to, to echo what Andrew said, Eric, so, so great to have you on. Uh, really awesome to, to put a voice to the, the face that I've seen on Twitter for all those years. So, uh, great to talk to you and yeah, I'm, I'm super excited to, uh, you know, learn more l l m stuff going forward, especially in playing with sudolang or, you know, if you ever do get around to writing a book about it.

Uh, That'd be really cool. Uh, but yeah, thanks again for coming on.
